{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call Analytics with Amazon Bedrock\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this example, you will use Amazon Bedrock to summarize and analyze the quality of a transcript of a customer service call using an LLM. A sample transcript is provided in the './data/' folder to get started. You can also use your own transcript file. This example utilizes Amazon Bedrock, Anthropic Claude 2.0 large language model (LLM), LangChain framework, and Pydantic parser to summarize and analyze the quality of customer service call transcripts. \n",
    "\n",
    "### Use case\n",
    "\n",
    "XYZ is a travel booking and vacation experience company. Customers can contact XYZ customer service representatives (CSRs) by phone to book new trips or modify existing reservations. These customer-CSR conversations are recorded, transcribed after the call ends, and analyzed by the call center management team to improve customer service processes and policies. The call transcription and analysis approach is also applicable for assessing customer interactions via email, chat, and other mediums.\n",
    "\n",
    "### How does this work?\n",
    "\n",
    "Transcript Ingestion\n",
    "- Customer service call transcripts are uploaded as JSON objects to an S3 bucket. Plain text formats are also supported.  \n",
    "\n",
    "Summarization Workflow\n",
    "- The transcript is retrieved from the S3 source bucket and fed as a prompt to Claude, an AI assistant from Anthropic.  \n",
    "- Leveraging natural language capabilities, Claude analyzes the dialogue and returns a JSON summary highlighting key discussion points and outcomes. This step uses LangChain for natural language processing and Pydantic for output structuring.\n",
    "\n",
    "Quality Analysis Workflow  \n",
    "- The full transcript is also analyzed by Claude against pre-defined quality criteria such as issue resolution, adherence to process standards, etc.  \n",
    "- Assessment results are returned by Claude in a JSON format conforming to Pydantic schemas. Powered by LangChain for natural language comprehension and Pydantic for output formatting.\n",
    "\n",
    "The two independent workflows allow simultaneous call summarization and quality analysis based on a single transcript ingestion event.\n",
    "\n",
    "![](./images/call-analytics-example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install LangChain\n",
    "%pip install langchain==0.1.16 --quiet\n",
    "#%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import BedrockChat\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from typing import List, Dict \n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "# Create Bedrock and S3 clients\n",
    "boto3_session=boto3.session.Session()\n",
    "bedrock_runtime = boto3_session.client(\"bedrock-runtime\")\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define LLM model\n",
    "#llm_modelId = \"anthropic.claude-v2\"\n",
    "#llm_modelId = \"anthropic.claude-v2:1\"\n",
    "llm_modelId = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "\n",
    "llm = BedrockChat(\n",
    "    model_id=llm_modelId,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 8000,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 1,\n",
    "    },\n",
    "    client=bedrock_runtime,\n",
    ")\n",
    "\n",
    "# Define S3 Location for customer service calls\n",
    "s3_bucket = 'your-bucket-name'\n",
    "\n",
    "if s3_bucket == 'your-bucket-name': \n",
    "    print (\"WARNING: PLease update 's3_bucket' with a name of your S3 bucket.\")\n",
    "s3_key_transcripts = 'call-analytics/call-transcript/'\n",
    "s3_key_summary = 'call-analytics/call-summary/'\n",
    "s3_key_score = 'call-analytics/call-score/'\n",
    "\n",
    "# Define call transcript file name\n",
    "call_transcript_file = 'Call Transcript Sample 1.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"call_ID\": \"12345\",\n",
      "  \"CSR_ID\": \"JaneDoe123\",\n",
      "  \"call_date\": \"2024-02-01\",\n",
      "  \"call_time\": \"02:16:43\",\n",
      "  \"call_transcript\": [\n",
      "    \"CSR: Thank you for calling ABC Travel, this is Jane. How may I assist you today? \",\n",
      "    \"Customer: Yes, I need help with a reservation I made last week. This is unacceptable service! \",\n",
      "    \"CSR: I apologize for the trouble. May I have your name and reservation number to look up your booking? \",\n",
      "    \"Customer: It's John Smith. My reservation number is 012345. I booked a trip to Hawaii last week and just got an email that my flight was canceled! This is ridiculous. \",\n",
      "    \"CSR: Let me take a look at your reservation here Mr. Smith. I see that your flight from Chicago to Honolulu on March 15th was indeed canceled by the airline. I do apologize for this inconvenience. \",\n",
      "    \"Customer: This is unbelievable! I booked this trip months ago. How could you just cancel my flight like that? I took time off work and made so many plans. This is completely unacceptable! \",\n",
      "    \"CSR: You're absolutely right, having a flight canceled can be very disruptive. As your travel agent, I want to do everything I can to get this fixed for you right away. It looks like the airline has rebooked you on a flight that leaves a few hours later on the same day. I know that's still an inconvenience though. Let me see what other options may be available. \",\n",
      "    \"Customer: This is ridiculous. I should get a full refund if you're going to cancel my flight like that. I don't want another flight, I just want my money back! \",\n",
      "    \"CSR: I completely understand your frustration, Mr. Smith. Since this cancellation was initiated by the airline, you are entitled to a full refund if you prefer not to be rebooked. I can definitely process that refund for the flight cost right away. How about the hotel and other portions of your trip - would you like for me to look into refunds or changes for those as well? My goal is to make sure you are completely satisfied. \",\n",
      "    \"Customer: This is unacceptable. I spent so much money on this trip and now it's ruined. I want a full refund for everything - the flight, the hotel, the car rental. You need to fix this! \",\n",
      "    \"CSR: You're absolutely right, Mr. Smith. Let me process full refunds for your entire trip booking right now. I see you booked 2 roundtrip flights, 5 nights hotel in Honolulu, and a 7 day car rental. I will get all of those refunded in full immediately. You should see the refund hit your credit card in 3-5 business days. I sincerely apologize that we had to cancel a portion of your trip. Providing a seamless travel experience is our top priority, so I appreciate you bringing this issue to my attention. \",\n",
      "    \"Customer: How could you let this happen? I booked my trip so far in advance specifically to avoid problems! Now everything is ruined and I had to waste my time calling you to get this fixed. This is the worst service ever. \",\n",
      "    \"CSR: Mr. Smith, I fully understand why you are upset about having your trip canceled. As a valued customer, you should be able to trust that your travel plans will go smoothly when you book with us. This situation absolutely falls short of our service standards. To make things right, I would like to offer you a $200 travel voucher that can be used on a future trip as an apology for this major inconvenience. Would that help restore your confidence in our company? \",\n",
      "    \"Customer: I don't want a voucher, I just want you to do your job! This is unbelievable. I need to speak to a supervisor immediately. \",\n",
      "    \"CSR: I certainly understand you wishing to speak to a supervisor to express your frustrations about this situation. Please hold for just one moment while I transfer you. Again, I sincerely apologize that we failed to meet expectations on this booking. We value you as our customer and want to regain your trust. Please hold and a supervisor will be right with you. \",\n",
      "    \"Supervisor: Hello Mr. Smith, this is Sarah the supervisor. I understand you've had trouble with your recent booking to Hawaii. I want to sincerely apologize for the cancellation - I know how disruptive that must be. Jane briefed me on the situation and I see she processed full refunds for your trip. I completely understand your frustration. At ABC Travel, it is our top priority to deliver seamless travel experiences to our valued customers like yourself. We clearly dropped the ball and I take full responsibility for that. What else can I do to help restore your confidence in us moving forward? I'm happy to apply a credit for a future trip or look into any other options. \",\n",
      "    \"Customer: This has been a terrible experience. You should train your staff better so these problems don't happen. I expect much better service than this if I'm going to book through your company again. \",\n",
      "    \"Supervisor: You're absolutely right, Mr. Smith. The cancellation of your trip should not have happened. This is clearly an area where we need to improve our service and internal procedures. I will work with our team to assess what went wrong and implement better training around managing cancellations and rebookings. We value you as our customer and want to learn from this experience. I sincerely appreciate you taking the time to speak with me directly so we can improve. Please feel free to reach out to me personally anytime if you do choose to book future travel with ABC. My goal is to restore your confidence in us.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Read call transcript file either from the repository or from an S3 bucket\n",
    "\n",
    "##########################################################################\n",
    "# OPTION 1: read from ./data/ folder in the repository (default)\n",
    "##########################################################################\n",
    "transcripts = Path(\"data\")\n",
    "transcript = (transcripts / call_transcript_file).open(\"r\").read()\n",
    "\n",
    "##########################################################################\n",
    "# OPTION 2: read from S3 Location for customer service calls defined above\n",
    "##########################################################################\n",
    "#obj = s3.get_object(Bucket=s3_Bucket, Key=s3_Key_Transcripts + call_transcript_file)\n",
    "#transcript = obj['Body'].read()\n",
    "\n",
    "# Define variables to simplify code in subsequent steps \n",
    "transcript_dict = json.loads(transcript)\n",
    "call_date = json.loads (transcript)['call_date']\n",
    "call_time = json.loads (transcript)['call_time']\n",
    "\n",
    "print(json.dumps(transcript_dict, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Summarization\n",
    "\n",
    "In this step, we utilize the LangChain framework and Pydantic parser to generate LLM output in JSON format.\n",
    "\n",
    "Refer to [Pydantic parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic) on LangChain site for addtional details and examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a data schema for the LLM output with required attributes\n",
    "class CallSummary(BaseModel):\n",
    "    call_summary: str = Field(description=\"Call transcript summary: \")\n",
    "    key_takeaways: List[str] = Field(description=\"Call transcript key takeaways: \")\n",
    "    follow_up_actions: List[str] = Field(description=\"Call Transcript key action items: \")\n",
    "\n",
    "# Define Pydantic parser based on the data schema \n",
    "summarization_parser = PydanticOutputParser(pydantic_object=CallSummary)\n",
    "\n",
    "# Define a template for the LLM prompt with {format_instructions} and  {transcript} placeholder inputs\n",
    "summarization_template = \"\"\"\n",
    "\n",
    "Please provide a summary of the following call transcript provided between <transcript></transcript> tags. \n",
    "Capture key takeaways and specific follow up actions. \n",
    "Skip the preamble and go straight to the answer.\n",
    "\n",
    "Format your response per the instructions below: \n",
    "{format_instructions} \n",
    "\n",
    "<transcript>{transcript}</transcript>\n",
    "\"\"\"\n",
    "\n",
    "# Incorporate the format instructions into the LLM prompt based on the prompt template\n",
    "summarization_prompt = ChatPromptTemplate.from_template(summarization_template, partial_variables={\"format_instructions\": summarization_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['transcript'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['transcript'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"call_summary\": {\"title\": \"Call Summary\", \"description\": \"Call transcript summary: \", \"type\": \"string\"}, \"key_takeaways\": {\"title\": \"Key Takeaways\", \"description\": \"Call transcript key takeaways: \", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"follow_up_actions\": {\"title\": \"Follow Up Actions\", \"description\": \"Call Transcript key action items: \", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"call_summary\", \"key_takeaways\", \"follow_up_actions\"]}\\n```'}, template='\\n\\nPlease provide a summary of the following call transcript provided between <transcript></transcript> tags. \\nCapture key takeaways and specific follow up actions. \\nSkip the preamble and go straight to the answer.\\n\\nFormat your response per the instructions below: \\n{format_instructions} \\n\\n<transcript>{transcript}</transcript>\\n'))]\n"
     ]
    }
   ],
   "source": [
    "# Review the content of the prompt with format instructions (notice the JSON example generated by Pydantic parser)\n",
    "print (summarization_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert the call transcript text from 'list' to 'string' format\n",
    "def process_transcript(transcript:str) -> str:\n",
    "    json_transcript = json.loads(transcript)\n",
    "    call_transcript = \"\\n\".join(json_transcript.get(\"call_transcript\", []))\n",
    "\n",
    "    return call_transcript\n",
    "\n",
    "# Construct the chain by essembing all required components using LangChain '|' operator\n",
    "summarization_chain = {\"transcript\": RunnableLambda(process_transcript)} | summarization_prompt | llm | summarization_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"call_transcript\": [\"CSR: Thank you for calling ABC Travel, this is Jane. How may I assist you today? \", \"Customer: Yes, I need help with a reservation I made last week. This is unacceptable service! \", \"CSR: I apologize for the trouble. May I have your name and reservation number to look up your booking? \", \"Customer: It's John Smith. My reservation number is 012345. I booked a trip to Hawaii last week and just got an email that my flight was canceled! This is ridiculous. \", \"CSR: Let me take a look at your reservation here Mr. Smith. I see that your flight from Chicago to Honolulu on March 15th was indeed canceled by the airline. I do apologize for this inconvenience. \", \"Customer: This is unbelievable! I booked this trip months ago. How could you just cancel my flight like that? I took time off work and made so many plans. This is completely unacceptable! \", \"CSR: You're absolutely right, having a flight canceled can be very disruptive. As your travel agent, I want to do everything I can to get this fixed for you right away. It looks like the airline has rebooked you on a flight that leaves a few hours later on the same day. I know that's still an inconvenience though. Let me see what other options may be available. \", \"Customer: This is ridiculous. I should get a full refund if you're going to cancel my flight like that. I don't want another flight, I just want my money back! \", \"CSR: I completely understand your frustration, Mr. Smith. Since this cancellation was initiated by the airline, you are entitled to a full refund if you prefer not to be rebooked. I can definitely process that refund for the flight cost right away. How about the hotel and other portions of your trip - would you like for me to look into refunds or changes for those as well? My goal is to make sure you are completely satisfied. \", \"Customer: This is unacceptable. I spent so much money on this trip and now it's ruined. I want a full refund for everything - the flight, the hotel, the car rental. You need to fix this! \", \"CSR: You're absolutely right, Mr. Smith. Let me process full refunds for your entire trip booking right now. I see you booked 2 roundtrip flights, 5 nights hotel in Honolulu, and a 7 day car rental. I will get all of those refunded in full immediately. You should see the refund hit your credit card in 3-5 business days. I sincerely apologize that we had to cancel a portion of your trip. Providing a seamless travel experience is our top priority, so I appreciate you bringing this issue to my attention. \", \"Customer: How could you let this happen? I booked my trip so far in advance specifically to avoid problems! Now everything is ruined and I had to waste my time calling you to get this fixed. This is the worst service ever. \", \"CSR: Mr. Smith, I fully understand why you are upset about having your trip canceled. As a valued customer, you should be able to trust that your travel plans will go smoothly when you book with us. This situation absolutely falls short of our service standards. To make things right, I would like to offer you a $200 travel voucher that can be used on a future trip as an apology for this major inconvenience. Would that help restore your confidence in our company? \", \"Customer: I don't want a voucher, I just want you to do your job! This is unbelievable. I need to speak to a supervisor immediately. \", \"CSR: I certainly understand you wishing to speak to a supervisor to express your frustrations about this situation. Please hold for just one moment while I transfer you. Again, I sincerely apologize that we failed to meet expectations on this booking. We value you as our customer and want to regain your trust. Please hold and a supervisor will be right with you. \", \"Supervisor: Hello Mr. Smith, this is Sarah the supervisor. I understand you've had trouble with your recent booking to Hawaii. I want to sincerely apologize for the cancellation - I know how disruptive that must be. Jane briefed me on the situation and I see she processed full refunds for your trip. I completely understand your frustration. At ABC Travel, it is our top priority to deliver seamless travel experiences to our valued customers like yourself. We clearly dropped the ball and I take full responsibility for that. What else can I do to help restore your confidence in us moving forward? I'm happy to apply a credit for a future trip or look into any other options. \", \"Customer: This has been a terrible experience. You should train your staff better so these problems don't happen. I expect much better service than this if I'm going to book through your company again. \", \"Supervisor: You're absolutely right, Mr. Smith. The cancellation of your trip should not have happened. This is clearly an area where we need to improve our service and internal procedures. I will work with our team to assess what went wrong and implement better training around managing cancellations and rebookings. We value you as our customer and want to learn from this experience. I sincerely appreciate you taking the time to speak with me directly so we can improve. Please feel free to reach out to me personally anytime if you do choose to book future travel with ABC. My goal is to restore your confidence in us.\"]}\n"
     ]
    }
   ],
   "source": [
    "print (transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_summary\": \"The customer's flight to Hawaii was canceled by the airline, causing significant disruption to his travel plans. The customer service representative offered to rebook or provide a full refund. After some back-and-forth, the representative processed a full refund for the flight, hotel, and car rental. The supervisor apologized for the poor experience and offered a travel voucher, which the customer declined. The supervisor committed to improving training and procedures to prevent similar issues in the future.\", \"key_takeaways\": [\"The customer's flight was canceled by the airline, disrupting his travel plans\", \"The customer service representative offered rebooking options or a full refund\", \"After the customer insisted, a full refund was processed for the entire trip booking\", \"The supervisor apologized and offered a travel voucher, which the customer declined\", \"The supervisor acknowledged the need for better training and procedures\"], \"follow_up_actions\": [\"Assess what went wrong with this booking that led to the cancellation\", \"Implement improved training for customer service staff on handling cancellations and rebookings\", \"Review internal procedures related to managing airline cancellations and customer communication\", \"Follow up with the customer if he books future travel to restore confidence\"]}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain; the output will contain the LLM output in JSON format\n",
    "summary = summarization_chain.invoke(transcript)\n",
    "\n",
    "print (summary.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Summary:\n",
      "The customer's flight to Hawaii was canceled by the airline, causing significant disruption to his travel plans. The customer service representative offered to rebook or provide a full refund. After some back-and-forth, the representative processed a full refund for the flight, hotel, and car rental. The supervisor apologized for the poor experience and offered a travel voucher, which the customer declined. The supervisor committed to improving training and procedures to prevent similar issues in the future.\n",
      "\n",
      "Key Takeaways:\n",
      "-The customer's flight was canceled by the airline, disrupting his travel plans\n",
      "-The customer service representative offered rebooking options or a full refund\n",
      "-After the customer insisted, a full refund was processed for the entire trip booking\n",
      "-The supervisor apologized and offered a travel voucher, which the customer declined\n",
      "-The supervisor acknowledged the need for better training and procedures\n",
      "\n",
      "Follow Up Actions\n",
      "-Assess what went wrong with this booking that led to the cancellation\n",
      "-Implement improved training for customer service staff on handling cancellations and rebookings\n",
      "-Review internal procedures related to managing airline cancellations and customer communication\n",
      "-Follow up with the customer if he books future travel to restore confidence\n"
     ]
    }
   ],
   "source": [
    "# Extract the required values for preview: Call Summary, Key Takeaways, Follow Up Actions.\n",
    "call_summary = summary.call_summary\n",
    "key_takeaways = \"-\" + \"\\n-\".join(summary.key_takeaways)\n",
    "follow_up_actions = \"-\" + \"\\n-\".join(summary.follow_up_actions)\n",
    "\n",
    "print(f\"Call Summary:\\n{call_summary}\\n\\nKey Takeaways:\\n{key_takeaways}\\n\\nFollow Up Actions\\n{follow_up_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_summary\": \"The customer's flight to Hawaii was canceled by the airline, causing significant disruption to his travel plans. The customer service representative offered to rebook or provide a full refund. After some back-and-forth, the representative processed a full refund for the flight, hotel, and car rental. The supervisor apologized for the poor experience and offered a travel voucher, which the customer declined. The supervisor committed to improving training and procedures to prevent similar issues in the future.\", \"key_takeaways\": [\"The customer's flight was canceled by the airline, disrupting his travel plans\", \"The customer service representative offered rebooking options or a full refund\", \"After the customer insisted, a full refund was processed for the entire trip booking\", \"The supervisor apologized and offered a travel voucher, which the customer declined\", \"The supervisor acknowledged the need for better training and procedures\"], \"follow_up_actions\": [\"Assess what went wrong with this booking that led to the cancellation\", \"Implement improved training for customer service staff on handling cancellations and rebookings\", \"Review internal procedures related to managing airline cancellations and customer communication\", \"Follow up with the customer if he books future travel to restore confidence\"], \"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"llm_model\": \"anthropic.claude-3-sonnet-20240229-v1:0\"}\n",
      "Transcript summary written to S3:call-analytics/call-summary/Call Summary 2024-02-01 02:16:43.json\n"
     ]
    }
   ],
   "source": [
    "# Construct call summary as JSON object with all relevant attributes to be stored in S3\n",
    "bedrock_response = json.loads(summary.json())\n",
    "bedrock_response [\"call_ID\"] = transcript_dict['call_ID']\n",
    "bedrock_response [\"CSR_ID\"] = transcript_dict['CSR_ID']\n",
    "bedrock_response [\"call_date\"] = call_date\n",
    "bedrock_response [\"call_time\"] = call_time\n",
    "bedrock_response [\"llm_model\"] = llm_modelId\n",
    "bedrock_response = json.dumps (bedrock_response)\n",
    "print (bedrock_response)\n",
    "\n",
    "# Write Bedrock output text to S3 object  \n",
    "s3_key = s3_key_summary + \"Call Summary \" + call_date + \" \" + call_time + \".json\"\n",
    "s3.put_object(Body=bedrock_response, Bucket=s3_bucket, Key=s3_key )\n",
    "\n",
    "print(\"Transcript summary written to S3:\" + s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Quality Assessment\n",
    "In this step, we utilize the LangChain framework and Pydantic parser to generate LLM output in JSON format. However, we expand the formatting instructions and prompt complexity in comparison to the Call Summarization step to achieve more tailored results. Specificially:\n",
    "\n",
    "1. The prompt template provides a list of call quality assessment categories, each with a descriptive explanation of what should be evaluated within that category. \n",
    "\n",
    "2. The data model for the LLM output has two levels of nesting to capture detailed scoring for each category. \n",
    "\n",
    "Refer to [Pydantic parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic) on LangChain site for addtional details and examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_template =  \"\"\"\n",
    "Evaluate call transcript against categories shown between <categories></categories> tags and provide score as 'High', 'Medium', 'Low' for each category.\n",
    "Skip the preamble and go straight to the answer.\n",
    "\n",
    "Format your response per the instructions below: \n",
    "{format_instructions} \n",
    "\n",
    "\n",
    "<categories>\n",
    "1. Communication Skills:\n",
    " - Clarity: How clearly and concisely does the CSR communicate information?\n",
    " - Active Listening: Does the CSR actively listen to the customer's concerns and questions?\n",
    " - Empathy: How well does the CSR demonstrate empathy and understanding towards the customer?\n",
    "\n",
    "2. Problem Resolution:\n",
    " - Effectiveness: How well did the CSR resolve the customer's issue or answer their question?\n",
    " - Timeliness: Was the issue resolved in a reasonable amount of time?\n",
    "\n",
    "3. Product Knowledge:\n",
    " - Familiarity: Does the CSR have a good understanding of the company's products and services?\n",
    " - Accuracy: How accurate and precise are the answers provided by the CSR?\n",
    "\n",
    "4. Professionalism:\n",
    " - Tone and Manner: How professional is the tone and manner of the CSR throughout the call?\n",
    " - Courtesy: Does the CSR maintain a courteous and respectful attitude towards the customer?\n",
    "\n",
    "5. Problem Escalation:\n",
    " - Recognition: Did the CSR recognize when an issue required escalation to a higher level of support?\n",
    " - Handoff: How smoothly and effectively did the CSR transfer the call if escalation was necessary?\n",
    "\n",
    "6. Resolution Follow-Up:\n",
    " - Follow-Up: Did the CSR provide information about any follow-up actions that would be taken?\n",
    " - Customer Satisfaction: Did the CSR inquire about the customer's satisfaction with the resolution?\n",
    "\n",
    "7. Efficiency:\n",
    " - Call Handling Time: Was the call resolved efficiently without unnecessary delays?\n",
    " - Multi-Tasking: If applicable, did the CSR effectively handle multiple tasks during the call?\n",
    "\n",
    "8. Adherence to Policies and Procedures:\n",
    " - Compliance: Did the CSR follow company policies and procedures in addressing the customer's issue?\n",
    " - Accuracy in Information: How well did the CSR adhere to the correct processes?\n",
    "\n",
    "9. Technical Competence:\n",
    " - System Use: Did the CSR effectively navigate and use the customer service tools and systems?\n",
    " - Troubleshooting: How adept is the CSR at troubleshooting technical issues?\n",
    "\n",
    "10. Customer Satisfaction:\n",
    " - Overall Satisfaction: How satisfied is the customer with the service received during the call?\n",
    " - Feedback: Did the CSR encourage the customer to provide feedback on the service?\n",
    "\n",
    "11. Language Proficiency:\n",
    " - Clarity of Language: Was the language used by the CSR easily understandable?\n",
    " - Language Appropriateness: Did the CSR use appropriate language for effective communication?\n",
    "\n",
    "12. Conflict Resolution:\n",
    " - Handling Difficult Customers: How well did the CSR manage and resolve conflicts with upset or frustrated customers?\n",
    " - De-escalation Skills: Did the CSR employ de-escalation techniques when needed?\n",
    "<categories>\n",
    "\n",
    "Here is the call transcript:\n",
    "<transcript>{transcript}</transcript>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data schema for the LLM output with required attributes\n",
    "\n",
    "class ScoreValue(Enum):\n",
    "    High = \"High\"\n",
    "    Medium = \"Medium\"\n",
    "    Low = \"Low\"\n",
    "\n",
    "class Score(BaseModel):\n",
    "    score: ScoreValue\n",
    "    score_explanation: str\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    Communication_Skills: Score\n",
    "    Problem_Resolution: Score\n",
    "    Product_Knowledge: Score\n",
    "    Professionalism: Score\n",
    "    Problem_Escalation: Score\n",
    "    Resolution_Follow_Up: Score\n",
    "    Efficiency: Score\n",
    "    Adherence_to_Policies_and_Procedures: Score\n",
    "    Technical_Competence: Score\n",
    "    Customer_Satisfaction: Score\n",
    "    Language_Proficiency: Score\n",
    "    Conflict_Resolution: Score\n",
    "    \n",
    "# Define Pydantic parser based on data schema \n",
    "assessment_parser = PydanticOutputParser(pydantic_object=Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate the format instructions into the LLM prompt based on the prompt template\n",
    "assessment_prompt = ChatPromptTemplate.from_template(assessment_template, partial_variables={\"format_instructions\": assessment_parser.get_format_instructions()})\n",
    "\n",
    "# Construct the chain by essembing all required components via LangChain '|' operator\n",
    "assessment_chain = {\"transcript\": RunnableLambda(process_transcript)} | assessment_prompt | llm | assessment_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain; the output will contain the LLM output in JSON format\n",
    "call_assessment = assessment_chain.invoke(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication_Skills: score=High, explanation=The CSR communicated clearly, listened actively, and demonstrated empathy towards the frustrated customer.\n",
      "\n",
      "Problem_Resolution: score=High, explanation=The CSR effectively resolved the issue by processing a full refund for the canceled trip in a timely manner.\n",
      "\n",
      "Product_Knowledge: score=High, explanation=The CSR demonstrated good knowledge of the company's products, policies, and procedures related to flight cancellations and refunds.\n",
      "\n",
      "Professionalism: score=High, explanation=The CSR maintained a professional, courteous tone and manner throughout the difficult interaction.\n",
      "\n",
      "Problem_Escalation: score=High, explanation=The CSR recognized when the issue required escalation to a supervisor and transferred the call smoothly.\n",
      "\n",
      "Resolution_Follow_Up: score=Medium, explanation=The CSR did not explicitly mention any follow-up actions, but did offer a voucher to restore the customer's confidence.\n",
      "\n",
      "Efficiency: score=High, explanation=The call was handled efficiently, with the CSR processing the refund promptly.\n",
      "\n",
      "Adherence_to_Policies_and_Procedures: score=High, explanation=The CSR followed company policies and procedures correctly in addressing the flight cancellation and refund.\n",
      "\n",
      "Technical_Competence: score=High, explanation=The CSR demonstrated effective use of the customer service systems to look up the reservation and process the refund.\n",
      "\n",
      "Customer_Satisfaction: score=Medium, explanation=While the CSR resolved the issue, the customer remained frustrated with the overall experience.\n",
      "\n",
      "Language_Proficiency: score=High, explanation=The language used by the CSR was clear, easily understandable, and appropriate for the situation.\n",
      "\n",
      "Conflict_Resolution: score=High, explanation=The CSR handled the conflict with the upset customer professionally, employing de-escalation techniques and offering appropriate resolutions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview score values for each category provided in the LLM output\n",
    "for category, score in call_assessment:\n",
    "    print(f\"{category}: score={score.score.value}, explanation={score.score_explanation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{\"Communication_Skills\": {\"score\": \"High\", \"score_explanation\": \"The CSR communicated clearly, listened actively, and demonstrated empathy towards the frustrated customer.\"}, \"Problem_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR effectively resolved the issue by processing a full refund for the canceled trip in a timely manner.\"}, \"Product_Knowledge\": {\"score\": \"High\", \"score_explanation\": \"The CSR demonstrated good knowledge of the company's products, policies, and procedures related to flight cancellations and refunds.\"}, \"Professionalism\": {\"score\": \"High\", \"score_explanation\": \"The CSR maintained a professional, courteous tone and manner throughout the difficult interaction.\"}, \"Problem_Escalation\": {\"score\": \"High\", \"score_explanation\": \"The CSR recognized when the issue required escalation to a supervisor and transferred the call smoothly.\"}, \"Resolution_Follow_Up\": {\"score\": \"Medium\", \"score_explanation\": \"The CSR did not explicitly mention any follow-up actions, but did offer a voucher to restore the customer's confidence.\"}, \"Efficiency\": {\"score\": \"High\", \"score_explanation\": \"The call was handled efficiently, with the CSR processing the refund promptly.\"}, \"Adherence_to_Policies_and_Procedures\": {\"score\": \"High\", \"score_explanation\": \"The CSR followed company policies and procedures correctly in addressing the flight cancellation and refund.\"}, \"Technical_Competence\": {\"score\": \"High\", \"score_explanation\": \"The CSR demonstrated effective use of the customer service systems to look up the reservation and process the refund.\"}, \"Customer_Satisfaction\": {\"score\": \"Medium\", \"score_explanation\": \"While the CSR resolved the issue, the customer remained frustrated with the overall experience.\"}, \"Language_Proficiency\": {\"score\": \"High\", \"score_explanation\": \"The language used by the CSR was clear, easily understandable, and appropriate for the situation.\"}, \"Conflict_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR handled the conflict with the upset customer professionally, employing de-escalation techniques and offering appropriate resolutions.\"}}\n"
     ]
    }
   ],
   "source": [
    "# Preview content of the call_assessment JSON object\n",
    "print (type(json.loads(call_assessment.json())))\n",
    "print (call_assessment.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Communication_Skills\": {\"score\": \"High\", \"score_explanation\": \"The CSR communicated clearly, listened actively, and demonstrated empathy towards the frustrated customer.\"}, \"Problem_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR effectively resolved the issue by processing a full refund for the canceled trip in a timely manner.\"}, \"Product_Knowledge\": {\"score\": \"High\", \"score_explanation\": \"The CSR demonstrated good knowledge of the company's products, policies, and procedures related to flight cancellations and refunds.\"}, \"Professionalism\": {\"score\": \"High\", \"score_explanation\": \"The CSR maintained a professional, courteous tone and manner throughout the difficult interaction.\"}, \"Problem_Escalation\": {\"score\": \"High\", \"score_explanation\": \"The CSR recognized when the issue required escalation to a supervisor and transferred the call smoothly.\"}, \"Resolution_Follow_Up\": {\"score\": \"Medium\", \"score_explanation\": \"The CSR did not explicitly mention any follow-up actions, but did offer a voucher to restore the customer's confidence.\"}, \"Efficiency\": {\"score\": \"High\", \"score_explanation\": \"The call was handled efficiently, with the CSR processing the refund promptly.\"}, \"Adherence_to_Policies_and_Procedures\": {\"score\": \"High\", \"score_explanation\": \"The CSR followed company policies and procedures correctly in addressing the flight cancellation and refund.\"}, \"Technical_Competence\": {\"score\": \"High\", \"score_explanation\": \"The CSR demonstrated effective use of the customer service systems to look up the reservation and process the refund.\"}, \"Customer_Satisfaction\": {\"score\": \"Medium\", \"score_explanation\": \"While the CSR resolved the issue, the customer remained frustrated with the overall experience.\"}, \"Language_Proficiency\": {\"score\": \"High\", \"score_explanation\": \"The language used by the CSR was clear, easily understandable, and appropriate for the situation.\"}, \"Conflict_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR handled the conflict with the upset customer professionally, employing de-escalation techniques and offering appropriate resolutions.\"}, \"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"llm_model\": \"anthropic.claude-3-sonnet-20240229-v1:0\"}\n",
      "Transcript score assessment written to S3:call-analytics/call-score/Call score 2024-02-01 02:16:43.json\n"
     ]
    }
   ],
   "source": [
    "# Construct the call summary as JSON object with all relevant attributes and save it to S3\n",
    "bedrock_response = json.loads(call_assessment.json())\n",
    "bedrock_response [\"call_ID\"] = transcript_dict['call_ID']\n",
    "bedrock_response [\"CSR_ID\"] = transcript_dict['CSR_ID']\n",
    "bedrock_response [\"call_date\"] = call_date\n",
    "bedrock_response [\"call_time\"] = call_time\n",
    "bedrock_response [\"llm_model\"] = llm_modelId\n",
    "bedrock_response = json.dumps (bedrock_response)\n",
    "print (bedrock_response)\n",
    "\n",
    "# Write Bedrock output text to S3 object  \n",
    "s3_key = s3_key_score + \"Call score \" + call_date + \" \" + call_time + \".json\"\n",
    "s3.put_object(Body=bedrock_response, Bucket=s3_bucket, Key=s3_key )\n",
    "\n",
    "print(\"Transcript score assessment written to S3:\" + s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End of the Notebook"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
