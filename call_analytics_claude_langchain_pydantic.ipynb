{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Call Analytics with Amazon Bedrock\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Overview\n",
    "\n",
    "In this example, you will use Amazon Bedrock to summarize and analyze the quality of a transcript of a customer service call using an LLM. A sample transcript is provided in the './data/' folder to get started. You can also use your own transcript file. This example utilizes Amazon Bedrock, Anthropic Claude 2.0 large language model (LLM), LangChain framework, and Pydantic parser to summarize and analyze the quality of customer service call transcripts. \n",
    "\n",
    "### Use case\n",
    "\n",
    "XYZ is a travel booking and vacation experience company. Customers can contact XYZ customer service representatives (CSRs) by phone to book new trips or modify existing reservations. These customer-CSR conversations are recorded, transcribed after the call ends, and analyzed by the call center management team to improve customer service processes and policies. The call transcription and analysis approach is also applicable for assessing customer interactions via email, chat, and other mediums.\n",
    "\n",
    "### How does this work?\n",
    "\n",
    "Transcript Ingestion\n",
    "- Customer service call transcripts are uploaded as JSON objects to an S3 bucket. Plain text formats are also supported.  \n",
    "\n",
    "Summarization Workflow\n",
    "- The transcript is retrieved from the S3 source bucket and fed as a prompt to Claude, an AI assistant from Anthropic.  \n",
    "- Leveraging natural language capabilities, Claude analyzes the dialogue and returns a JSON summary highlighting key discussion points and outcomes. This step uses LangChain for natural language processing and Pydantic for output structuring.\n",
    "\n",
    "Quality Analysis Workflow  \n",
    "- The full transcript is also analyzed by Claude against pre-defined quality criteria such as issue resolution, adherence to process standards, etc.  \n",
    "- Assessment results are returned by Claude in a JSON format conforming to Pydantic schemas. Powered by LangChain for natural language comprehension and Pydantic for output formatting.\n",
    "\n",
    "The two independent workflows allow simultaneous call summarization and quality analysis based on a single transcript ingestion event.\n",
    "\n",
    "![](./images/call-analytics-example.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install LangChain\n",
    "%pip install langchain==0.1.16 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: PLease update 's3_bucket' with a name of your S3 bucket.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import BedrockChat\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from typing import List, Dict \n",
    "from enum import Enum\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import json\n",
    "import boto3\n",
    "from pathlib import Path\n",
    "\n",
    "# Create Bedrock and S3 clients\n",
    "boto3_session=boto3.session.Session()\n",
    "bedrock_runtime = boto3_session.client(\"bedrock-runtime\")\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Define LLM model \n",
    "#llm_modelId = \"anthropic.claude-v2\"\n",
    "llm_modelId = \"anthropic.claude-v2:1\"\n",
    "\n",
    "llm = BedrockChat(\n",
    "    model_id=llm_modelId,\n",
    "    model_kwargs={\n",
    "        \"max_tokens\": 8000,\n",
    "        \"stop_sequences\": [\"\\n\\nHuman:\"],\n",
    "        \"temperature\": 0.4,\n",
    "        \"top_p\": 1,\n",
    "    },\n",
    "    client=bedrock_runtime,\n",
    ")\n",
    "\n",
    "# Define S3 Location for customer service calls\n",
    "s3_bucket = 'your-bucket-name' \n",
    "if s3_bucket == 'your-bucket-name': \n",
    "    print (\"WARNING: PLease update 's3_bucket' with a name of your S3 bucket.\")\n",
    "s3_key_transcripts = 'call-analytics/call-transcript/'\n",
    "s3_key_summary = 'call-analytics/call-summary/'\n",
    "s3_key_score = 'call-analytics/call-score/'\n",
    "\n",
    "# Define call transcript file name\n",
    "call_transcript_file = 'Call Transcript Sample 1.json'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"call_ID\": \"12345\",\n",
      "  \"CSR_ID\": \"JaneDoe123\",\n",
      "  \"call_date\": \"2024-02-01\",\n",
      "  \"call_time\": \"02:16:43\",\n",
      "  \"call_transcript\": [\n",
      "    \"CSR: Thank you for calling ABC Travel, this is Jane. How may I assist you today? \",\n",
      "    \"Customer: Yes, I need help with a reservation I made last week. This is unacceptable service! \",\n",
      "    \"CSR: I apologize for the trouble. May I have your name and reservation number to look up your booking? \",\n",
      "    \"Customer: It's John Smith. My reservation number is 012345. I booked a trip to Hawaii last week and just got an email that my flight was canceled! This is ridiculous. \",\n",
      "    \"CSR: Let me take a look at your reservation here Mr. Smith. I see that your flight from Chicago to Honolulu on March 15th was indeed canceled by the airline. I do apologize for this inconvenience. \",\n",
      "    \"Customer: This is unbelievable! I booked this trip months ago. How could you just cancel my flight like that? I took time off work and made so many plans. This is completely unacceptable! \",\n",
      "    \"CSR: You're absolutely right, having a flight canceled can be very disruptive. As your travel agent, I want to do everything I can to get this fixed for you right away. It looks like the airline has rebooked you on a flight that leaves a few hours later on the same day. I know that's still an inconvenience though. Let me see what other options may be available. \",\n",
      "    \"Customer: This is ridiculous. I should get a full refund if you're going to cancel my flight like that. I don't want another flight, I just want my money back! \",\n",
      "    \"CSR: I completely understand your frustration, Mr. Smith. Since this cancellation was initiated by the airline, you are entitled to a full refund if you prefer not to be rebooked. I can definitely process that refund for the flight cost right away. How about the hotel and other portions of your trip - would you like for me to look into refunds or changes for those as well? My goal is to make sure you are completely satisfied. \",\n",
      "    \"Customer: This is unacceptable. I spent so much money on this trip and now it's ruined. I want a full refund for everything - the flight, the hotel, the car rental. You need to fix this! \",\n",
      "    \"CSR: You're absolutely right, Mr. Smith. Let me process full refunds for your entire trip booking right now. I see you booked 2 roundtrip flights, 5 nights hotel in Honolulu, and a 7 day car rental. I will get all of those refunded in full immediately. You should see the refund hit your credit card in 3-5 business days. I sincerely apologize that we had to cancel a portion of your trip. Providing a seamless travel experience is our top priority, so I appreciate you bringing this issue to my attention. \",\n",
      "    \"Customer: How could you let this happen? I booked my trip so far in advance specifically to avoid problems! Now everything is ruined and I had to waste my time calling you to get this fixed. This is the worst service ever. \",\n",
      "    \"CSR: Mr. Smith, I fully understand why you are upset about having your trip canceled. As a valued customer, you should be able to trust that your travel plans will go smoothly when you book with us. This situation absolutely falls short of our service standards. To make things right, I would like to offer you a $200 travel voucher that can be used on a future trip as an apology for this major inconvenience. Would that help restore your confidence in our company? \",\n",
      "    \"Customer: I don't want a voucher, I just want you to do your job! This is unbelievable. I need to speak to a supervisor immediately. \",\n",
      "    \"CSR: I certainly understand you wishing to speak to a supervisor to express your frustrations about this situation. Please hold for just one moment while I transfer you. Again, I sincerely apologize that we failed to meet expectations on this booking. We value you as our customer and want to regain your trust. Please hold and a supervisor will be right with you. \",\n",
      "    \"Supervisor: Hello Mr. Smith, this is Sarah the supervisor. I understand you've had trouble with your recent booking to Hawaii. I want to sincerely apologize for the cancellation - I know how disruptive that must be. Jane briefed me on the situation and I see she processed full refunds for your trip. I completely understand your frustration. At ABC Travel, it is our top priority to deliver seamless travel experiences to our valued customers like yourself. We clearly dropped the ball and I take full responsibility for that. What else can I do to help restore your confidence in us moving forward? I'm happy to apply a credit for a future trip or look into any other options. \",\n",
      "    \"Customer: This has been a terrible experience. You should train your staff better so these problems don't happen. I expect much better service than this if I'm going to book through your company again. \",\n",
      "    \"Supervisor: You're absolutely right, Mr. Smith. The cancellation of your trip should not have happened. This is clearly an area where we need to improve our service and internal procedures. I will work with our team to assess what went wrong and implement better training around managing cancellations and rebookings. We value you as our customer and want to learn from this experience. I sincerely appreciate you taking the time to speak with me directly so we can improve. Please feel free to reach out to me personally anytime if you do choose to book future travel with ABC. My goal is to restore your confidence in us.\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Read call transcript file either from the repository or from an S3 bucket\n",
    "\n",
    "##########################################################################\n",
    "# OPTION 1: read from ./data/ folder in the repository (default)\n",
    "##########################################################################\n",
    "transcripts = Path(\"data\")\n",
    "transcript = (transcripts / call_transcript_file).open(\"r\").read()\n",
    "\n",
    "##########################################################################\n",
    "# OPTION 2: read from S3 Location for customer service calls defined above\n",
    "##########################################################################\n",
    "#obj = s3.get_object(Bucket=s3_Bucket, Key=s3_Key_Transcripts + call_transcript_file)\n",
    "#transcript = obj['Body'].read()\n",
    "\n",
    "# Define variables to simplify code in subsequent steps \n",
    "transcript_dict = json.loads(transcript)\n",
    "call_date = json.loads (transcript)['call_date']\n",
    "call_time = json.loads (transcript)['call_time']\n",
    "\n",
    "print(json.dumps(transcript_dict, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Call Summarization\n",
    "\n",
    "In this step, we utilize the LangChain framework and Pydantic parser to generate LLM output in JSON format.\n",
    "\n",
    "Refer to [Pydantic parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic) on LangChain site for addtional details and examples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a data schema for the LLM output with required attributes\n",
    "class CallSummary(BaseModel):\n",
    "    call_summary: str = Field(description=\"Call transcript summary: \")\n",
    "    key_takeaways: List[str] = Field(description=\"Call transcript key takeaways: \")\n",
    "    follow_up_actions: List[str] = Field(description=\"Call Transcript key action items: \")\n",
    "\n",
    "# Define Pydantic parser based on the data schema \n",
    "summarization_parser = PydanticOutputParser(pydantic_object=CallSummary)\n",
    "\n",
    "# Define a template for the LLM prompt with {format_instructions} and  {transcript} placeholder inputs\n",
    "summarization_template = \"\"\"\n",
    "\n",
    "Please provide a summary of the following call transcript provided between <transcript></transcript> tags. \n",
    "Capture key takeaways and specific follow up actions. \n",
    "\n",
    "Format your response per the instructions below: \n",
    "{format_instructions} \n",
    "\n",
    "<transcript>{transcript}</transcript>\n",
    "\"\"\"\n",
    "\n",
    "# Incorporate the format instructions into the LLM prompt based on the prompt template\n",
    "summarization_prompt = ChatPromptTemplate.from_template(summarization_template, partial_variables={\"format_instructions\": summarization_parser.get_format_instructions()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['transcript'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['transcript'], partial_variables={'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"call_summary\": {\"title\": \"Call Summary\", \"description\": \"Call transcript summary: \", \"type\": \"string\"}, \"key_takeaways\": {\"title\": \"Key Takeaways\", \"description\": \"Call transcript key takeaways: \", \"type\": \"array\", \"items\": {\"type\": \"string\"}}, \"follow_up_actions\": {\"title\": \"Follow Up Actions\", \"description\": \"Call Transcript key action items: \", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"call_summary\", \"key_takeaways\", \"follow_up_actions\"]}\\n```'}, template='\\n\\nPlease provide a summary of the following call transcript provided between <transcript></transcript> tags. \\nCapture key takeaways and specific follow up actions. \\n\\nFormat your response per the instructions below: \\n{format_instructions} \\n\\n<transcript>{transcript}</transcript>\\n'))]\n"
     ]
    }
   ],
   "source": [
    "# Review the content of the prompt with format instructions (notice the JSON example generated by Pydantic parser)\n",
    "print (summarization_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to convert the call transcript text from 'list' to 'string' format\n",
    "def process_transcript(transcript:str) -> str:\n",
    "    json_transcript = json.loads(transcript)\n",
    "    call_transcript = \"\\n\".join(json_transcript.get(\"call_transcript\", []))\n",
    "\n",
    "    return call_transcript\n",
    "\n",
    "# Construct the chain by essembing all required components using LangChain '|' operator\n",
    "summarization_chain = {\"transcript\": RunnableLambda(process_transcript)} | summarization_prompt | llm | summarization_parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"call_transcript\": [\"CSR: Thank you for calling ABC Travel, this is Jane. How may I assist you today? \", \"Customer: Yes, I need help with a reservation I made last week. This is unacceptable service! \", \"CSR: I apologize for the trouble. May I have your name and reservation number to look up your booking? \", \"Customer: It's John Smith. My reservation number is 012345. I booked a trip to Hawaii last week and just got an email that my flight was canceled! This is ridiculous. \", \"CSR: Let me take a look at your reservation here Mr. Smith. I see that your flight from Chicago to Honolulu on March 15th was indeed canceled by the airline. I do apologize for this inconvenience. \", \"Customer: This is unbelievable! I booked this trip months ago. How could you just cancel my flight like that? I took time off work and made so many plans. This is completely unacceptable! \", \"CSR: You're absolutely right, having a flight canceled can be very disruptive. As your travel agent, I want to do everything I can to get this fixed for you right away. It looks like the airline has rebooked you on a flight that leaves a few hours later on the same day. I know that's still an inconvenience though. Let me see what other options may be available. \", \"Customer: This is ridiculous. I should get a full refund if you're going to cancel my flight like that. I don't want another flight, I just want my money back! \", \"CSR: I completely understand your frustration, Mr. Smith. Since this cancellation was initiated by the airline, you are entitled to a full refund if you prefer not to be rebooked. I can definitely process that refund for the flight cost right away. How about the hotel and other portions of your trip - would you like for me to look into refunds or changes for those as well? My goal is to make sure you are completely satisfied. \", \"Customer: This is unacceptable. I spent so much money on this trip and now it's ruined. I want a full refund for everything - the flight, the hotel, the car rental. You need to fix this! \", \"CSR: You're absolutely right, Mr. Smith. Let me process full refunds for your entire trip booking right now. I see you booked 2 roundtrip flights, 5 nights hotel in Honolulu, and a 7 day car rental. I will get all of those refunded in full immediately. You should see the refund hit your credit card in 3-5 business days. I sincerely apologize that we had to cancel a portion of your trip. Providing a seamless travel experience is our top priority, so I appreciate you bringing this issue to my attention. \", \"Customer: How could you let this happen? I booked my trip so far in advance specifically to avoid problems! Now everything is ruined and I had to waste my time calling you to get this fixed. This is the worst service ever. \", \"CSR: Mr. Smith, I fully understand why you are upset about having your trip canceled. As a valued customer, you should be able to trust that your travel plans will go smoothly when you book with us. This situation absolutely falls short of our service standards. To make things right, I would like to offer you a $200 travel voucher that can be used on a future trip as an apology for this major inconvenience. Would that help restore your confidence in our company? \", \"Customer: I don't want a voucher, I just want you to do your job! This is unbelievable. I need to speak to a supervisor immediately. \", \"CSR: I certainly understand you wishing to speak to a supervisor to express your frustrations about this situation. Please hold for just one moment while I transfer you. Again, I sincerely apologize that we failed to meet expectations on this booking. We value you as our customer and want to regain your trust. Please hold and a supervisor will be right with you. \", \"Supervisor: Hello Mr. Smith, this is Sarah the supervisor. I understand you've had trouble with your recent booking to Hawaii. I want to sincerely apologize for the cancellation - I know how disruptive that must be. Jane briefed me on the situation and I see she processed full refunds for your trip. I completely understand your frustration. At ABC Travel, it is our top priority to deliver seamless travel experiences to our valued customers like yourself. We clearly dropped the ball and I take full responsibility for that. What else can I do to help restore your confidence in us moving forward? I'm happy to apply a credit for a future trip or look into any other options. \", \"Customer: This has been a terrible experience. You should train your staff better so these problems don't happen. I expect much better service than this if I'm going to book through your company again. \", \"Supervisor: You're absolutely right, Mr. Smith. The cancellation of your trip should not have happened. This is clearly an area where we need to improve our service and internal procedures. I will work with our team to assess what went wrong and implement better training around managing cancellations and rebookings. We value you as our customer and want to learn from this experience. I sincerely appreciate you taking the time to speak with me directly so we can improve. Please feel free to reach out to me personally anytime if you do choose to book future travel with ABC. My goal is to restore your confidence in us.\"]}\n"
     ]
    }
   ],
   "source": [
    "print (transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_summary\": \"The customer booked a trip to Hawaii that got canceled. The CSR apologized and processed full refunds. The customer was very frustrated and asked for a supervisor. The supervisor also apologized, took responsibility, and offered future credits. The customer said the experience was terrible and the company needs better training.\", \"key_takeaways\": [\"Customer's flight to Hawaii was canceled by the airline\", \"Customer was offered rebooking but requested full refunds\", \"Customer expressed frustration at multiple points during call\", \"Supervisor took responsibility and offered credits for future travel\"], \"follow_up_actions\": [\"Process full refund for customer's canceled Hawaii trip\", \"Assess internal procedures around managing cancellations\", \"Implement better training for staff on handling cancellations\", \"Follow up with customer regarding future travel credits\"]}\n"
     ]
    }
   ],
   "source": [
    "# Invoke the chain; the output will contain the LLM output in JSON format\n",
    "summary = summarization_chain.invoke(transcript)\n",
    "\n",
    "print (summary.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Call Summary:\n",
      "The customer booked a trip to Hawaii that got canceled. The CSR apologized and processed full refunds. The customer was very frustrated and asked for a supervisor. The supervisor also apologized, took responsibility, and offered future credits. The customer said the experience was terrible and the company needs better training.\n",
      "\n",
      "Key Takeaways:\n",
      "-Customer's flight to Hawaii was canceled by the airline\n",
      "-Customer was offered rebooking but requested full refunds\n",
      "-Customer expressed frustration at multiple points during call\n",
      "-Supervisor took responsibility and offered credits for future travel\n",
      "\n",
      "Follow Up Actions\n",
      "-Process full refund for customer's canceled Hawaii trip\n",
      "-Assess internal procedures around managing cancellations\n",
      "-Implement better training for staff on handling cancellations\n",
      "-Follow up with customer regarding future travel credits\n"
     ]
    }
   ],
   "source": [
    "# Extract the required values for preview: Call Summary, Key Takeaways, Follow Up Actions.\n",
    "call_summary = summary.call_summary\n",
    "key_takeaways = \"-\" + \"\\n-\".join(summary.key_takeaways)\n",
    "follow_up_actions = \"-\" + \"\\n-\".join(summary.follow_up_actions)\n",
    "\n",
    "print(f\"Call Summary:\\n{call_summary}\\n\\nKey Takeaways:\\n{key_takeaways}\\n\\nFollow Up Actions\\n{follow_up_actions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"call_summary\": \"The customer booked a trip to Hawaii that got canceled. The CSR apologized and processed full refunds. The customer was very frustrated and asked for a supervisor. The supervisor also apologized, took responsibility, and offered future credits. The customer said the experience was terrible and the company needs better training.\", \"key_takeaways\": [\"Customer's flight to Hawaii was canceled by the airline\", \"Customer was offered rebooking but requested full refunds\", \"Customer expressed frustration at multiple points during call\", \"Supervisor took responsibility and offered credits for future travel\"], \"follow_up_actions\": [\"Process full refund for customer's canceled Hawaii trip\", \"Assess internal procedures around managing cancellations\", \"Implement better training for staff on handling cancellations\", \"Follow up with customer regarding future travel credits\"], \"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"llm_model\": \"anthropic.claude-v2:1\"}\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AllAccessDisabled) when calling the PutObject operation: All access to this object has been disabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Write Bedrock output text to S3 object  \u001b[39;00m\n\u001b[1;32m     12\u001b[0m s3_key \u001b[38;5;241m=\u001b[39m s3_key_summary \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall Summary \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m call_date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m call_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbedrock_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_key\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscript summary written to S3:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m s3_key)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AllAccessDisabled) when calling the PutObject operation: All access to this object has been disabled"
     ]
    }
   ],
   "source": [
    "# Construct call summary as JSON object with all relevant attributes to be stored in S3\n",
    "bedrock_response = json.loads(summary.json())\n",
    "bedrock_response [\"call_ID\"] = transcript_dict['call_ID']\n",
    "bedrock_response [\"CSR_ID\"] = transcript_dict['CSR_ID']\n",
    "bedrock_response [\"call_date\"] = call_date\n",
    "bedrock_response [\"call_time\"] = call_time\n",
    "bedrock_response [\"llm_model\"] = llm_modelId\n",
    "bedrock_response = json.dumps (bedrock_response)\n",
    "print (bedrock_response)\n",
    "\n",
    "# Write Bedrock output text to S3 object  \n",
    "s3_key = s3_key_summary + \"Call Summary \" + call_date + \" \" + call_time + \".json\"\n",
    "s3.put_object(Body=bedrock_response, Bucket=s3_bucket, Key=s3_key )\n",
    "\n",
    "print(\"Transcript summary written to S3:\" + s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call Quality Assessment\n",
    "In this step, we utilize the LangChain framework and Pydantic parser to generate LLM output in JSON format. However, we expand the formatting instructions and prompt complexity in comparison to the Call Summarization step to achieve more tailored results. Specificially:\n",
    "\n",
    "1. The prompt template provides a list of call quality assessment categories, each with a descriptive explanation of what should be evaluated within that category. \n",
    "\n",
    "2. The data model for the LLM output has two levels of nesting to capture detailed scoring for each category. \n",
    "\n",
    "Refer to [Pydantic parser](https://python.langchain.com/docs/modules/model_io/output_parsers/types/pydantic) on LangChain site for addtional details and examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessment_template =  \"\"\"\n",
    "Evaluate call transcript against categories shown between <categories></categories> tags and provide score as 'High', 'Medium', 'Low' for each category.\n",
    "\n",
    "Format your response per the instructions below: \n",
    "{format_instructions} \n",
    "\n",
    "\n",
    "<categories>\n",
    "1. Communication Skills:\n",
    " - Clarity: How clearly and concisely does the CSR communicate information?\n",
    " - Active Listening: Does the CSR actively listen to the customer's concerns and questions?\n",
    " - Empathy: How well does the CSR demonstrate empathy and understanding towards the customer?\n",
    "\n",
    "2. Problem Resolution:\n",
    " - Effectiveness: How well did the CSR resolve the customer's issue or answer their question?\n",
    " - Timeliness: Was the issue resolved in a reasonable amount of time?\n",
    "\n",
    "3. Product Knowledge:\n",
    " - Familiarity: Does the CSR have a good understanding of the company's products and services?\n",
    " - Accuracy: How accurate and precise are the answers provided by the CSR?\n",
    "\n",
    "4. Professionalism:\n",
    " - Tone and Manner: How professional is the tone and manner of the CSR throughout the call?\n",
    " - Courtesy: Does the CSR maintain a courteous and respectful attitude towards the customer?\n",
    "\n",
    "5. Problem Escalation:\n",
    " - Recognition: Did the CSR recognize when an issue required escalation to a higher level of support?\n",
    " - Handoff: How smoothly and effectively did the CSR transfer the call if escalation was necessary?\n",
    "\n",
    "6. Resolution Follow-Up:\n",
    " - Follow-Up: Did the CSR provide information about any follow-up actions that would be taken?\n",
    " - Customer Satisfaction: Did the CSR inquire about the customer's satisfaction with the resolution?\n",
    "\n",
    "7. Efficiency:\n",
    " - Call Handling Time: Was the call resolved efficiently without unnecessary delays?\n",
    " - Multi-Tasking: If applicable, did the CSR effectively handle multiple tasks during the call?\n",
    "\n",
    "8. Adherence to Policies and Procedures:\n",
    " - Compliance: Did the CSR follow company policies and procedures in addressing the customer's issue?\n",
    " - Accuracy in Information: How well did the CSR adhere to the correct processes?\n",
    "\n",
    "9. Technical Competence:\n",
    " - System Use: Did the CSR effectively navigate and use the customer service tools and systems?\n",
    " - Troubleshooting: How adept is the CSR at troubleshooting technical issues?\n",
    "\n",
    "10. Customer Satisfaction:\n",
    " - Overall Satisfaction: How satisfied is the customer with the service received during the call?\n",
    " - Feedback: Did the CSR encourage the customer to provide feedback on the service?\n",
    "\n",
    "11. Language Proficiency:\n",
    " - Clarity of Language: Was the language used by the CSR easily understandable?\n",
    " - Language Appropriateness: Did the CSR use appropriate language for effective communication?\n",
    "\n",
    "12. Conflict Resolution:\n",
    " - Handling Difficult Customers: How well did the CSR manage and resolve conflicts with upset or frustrated customers?\n",
    " - De-escalation Skills: Did the CSR employ de-escalation techniques when needed?\n",
    "<categories>\n",
    "\n",
    "Here is the call transcript:\n",
    "<transcript>{transcript}</transcript>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a data schema for the LLM output with required attributes\n",
    "\n",
    "class ScoreValue(Enum):\n",
    "    High = \"High\"\n",
    "    Medium = \"Medium\"\n",
    "    Low = \"Low\"\n",
    "\n",
    "class Score(BaseModel):\n",
    "    score: ScoreValue\n",
    "    score_explanation: str\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    Communication_Skills: Score\n",
    "    Problem_Resolution: Score\n",
    "    Product_Knowledge: Score\n",
    "    Professionalism: Score\n",
    "    Problem_Escalation: Score\n",
    "    Resolution_Follow_Up: Score\n",
    "    Efficiency: Score\n",
    "    Adherence_to_Policies_and_Procedures: Score\n",
    "    Technical_Competence: Score\n",
    "    Customer_Satisfaction: Score\n",
    "    Language_Proficiency: Score\n",
    "    Conflict_Resolution: Score\n",
    "    \n",
    "# Define Pydantic parser based on data schema \n",
    "assessment_parser = PydanticOutputParser(pydantic_object=Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate the format instructions into the LLM prompt based on the prompt template\n",
    "assessment_prompt = ChatPromptTemplate.from_template(assessment_template, partial_variables={\"format_instructions\": assessment_parser.get_format_instructions()})\n",
    "\n",
    "# Construct the chain by essembing all required components via LangChain '|' operator\n",
    "assessment_chain = {\"transcript\": RunnableLambda(process_transcript)} | assessment_prompt | llm | assessment_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain; the output will contain the LLM output in JSON format\n",
    "call_assessment = assessment_chain.invoke(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communication_Skills: score=High, explanation=The CSR and supervisor communicated clearly, listened actively, and showed empathy. They apologized sincerely and took responsibility.\n",
      "\n",
      "Problem_Resolution: score=High, explanation=The CSR quickly resolved the issue by providing full refunds. The supervisor also offered credits for future travel.\n",
      "\n",
      "Product_Knowledge: score=High, explanation=The CSR was familiar with the policies around flight cancellations and refunds. The responses were accurate.\n",
      "\n",
      "Professionalism: score=High, explanation=Both the CSR and supervisor maintained a professional, courteous tone even when the customer was frustrated.\n",
      "\n",
      "Problem_Escalation: score=High, explanation=The CSR appropriately recognized the need to involve a supervisor. The handoff was smooth.\n",
      "\n",
      "Resolution_Follow_Up: score=High, explanation=The CSR provided clear follow-up on the refund status. The supervisor followed up on customer satisfaction.\n",
      "\n",
      "Efficiency: score=High, explanation=The issue was resolved quickly with no unnecessary delays.\n",
      "\n",
      "Adherence_to_Policies_and_Procedures: score=High, explanation=The CSR adhered properly to policies around flight cancellations and refunds.\n",
      "\n",
      "Technical_Competence: score=High, explanation=The CSR competently navigated the booking systems and policies.\n",
      "\n",
      "Customer_Satisfaction: score=Medium, explanation=The customer was still frustrated at the end, but the agents made efforts to resolve.\n",
      "\n",
      "Language_Proficiency: score=High, explanation=Clear, professional language used throughout the call.\n",
      "\n",
      "Conflict_Resolution: score=High, explanation=The CSR and supervisor employed empathy, de-escalation and solutions even when faced with an angry customer.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preview score values for each category provided in the LLM output\n",
    "for category, score in call_assessment:\n",
    "    print(f\"{category}: score={score.score.value}, explanation={score.score_explanation}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{\"Communication_Skills\": {\"score\": \"High\", \"score_explanation\": \"The CSR and supervisor communicated clearly, listened actively, and showed empathy. They apologized sincerely and took responsibility.\"}, \"Problem_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR quickly resolved the issue by providing full refunds. The supervisor also offered credits for future travel.\"}, \"Product_Knowledge\": {\"score\": \"High\", \"score_explanation\": \"The CSR was familiar with the policies around flight cancellations and refunds. The responses were accurate.\"}, \"Professionalism\": {\"score\": \"High\", \"score_explanation\": \"Both the CSR and supervisor maintained a professional, courteous tone even when the customer was frustrated.\"}, \"Problem_Escalation\": {\"score\": \"High\", \"score_explanation\": \"The CSR appropriately recognized the need to involve a supervisor. The handoff was smooth.\"}, \"Resolution_Follow_Up\": {\"score\": \"High\", \"score_explanation\": \"The CSR provided clear follow-up on the refund status. The supervisor followed up on customer satisfaction.\"}, \"Efficiency\": {\"score\": \"High\", \"score_explanation\": \"The issue was resolved quickly with no unnecessary delays.\"}, \"Adherence_to_Policies_and_Procedures\": {\"score\": \"High\", \"score_explanation\": \"The CSR adhered properly to policies around flight cancellations and refunds.\"}, \"Technical_Competence\": {\"score\": \"High\", \"score_explanation\": \"The CSR competently navigated the booking systems and policies.\"}, \"Customer_Satisfaction\": {\"score\": \"Medium\", \"score_explanation\": \"The customer was still frustrated at the end, but the agents made efforts to resolve.\"}, \"Language_Proficiency\": {\"score\": \"High\", \"score_explanation\": \"Clear, professional language used throughout the call.\"}, \"Conflict_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR and supervisor employed empathy, de-escalation and solutions even when faced with an angry customer.\"}}\n"
     ]
    }
   ],
   "source": [
    "# Preview content of the call_assessment JSON object\n",
    "print (type(json.loads(call_assessment.json())))\n",
    "print (call_assessment.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Communication_Skills\": {\"score\": \"High\", \"score_explanation\": \"The CSR and supervisor communicated clearly, listened actively, and showed empathy. They apologized sincerely and took responsibility.\"}, \"Problem_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR quickly resolved the issue by providing full refunds. The supervisor also offered credits for future travel.\"}, \"Product_Knowledge\": {\"score\": \"High\", \"score_explanation\": \"The CSR was familiar with the policies around flight cancellations and refunds. The responses were accurate.\"}, \"Professionalism\": {\"score\": \"High\", \"score_explanation\": \"Both the CSR and supervisor maintained a professional, courteous tone even when the customer was frustrated.\"}, \"Problem_Escalation\": {\"score\": \"High\", \"score_explanation\": \"The CSR appropriately recognized the need to involve a supervisor. The handoff was smooth.\"}, \"Resolution_Follow_Up\": {\"score\": \"High\", \"score_explanation\": \"The CSR provided clear follow-up on the refund status. The supervisor followed up on customer satisfaction.\"}, \"Efficiency\": {\"score\": \"High\", \"score_explanation\": \"The issue was resolved quickly with no unnecessary delays.\"}, \"Adherence_to_Policies_and_Procedures\": {\"score\": \"High\", \"score_explanation\": \"The CSR adhered properly to policies around flight cancellations and refunds.\"}, \"Technical_Competence\": {\"score\": \"High\", \"score_explanation\": \"The CSR competently navigated the booking systems and policies.\"}, \"Customer_Satisfaction\": {\"score\": \"Medium\", \"score_explanation\": \"The customer was still frustrated at the end, but the agents made efforts to resolve.\"}, \"Language_Proficiency\": {\"score\": \"High\", \"score_explanation\": \"Clear, professional language used throughout the call.\"}, \"Conflict_Resolution\": {\"score\": \"High\", \"score_explanation\": \"The CSR and supervisor employed empathy, de-escalation and solutions even when faced with an angry customer.\"}, \"call_ID\": \"12345\", \"CSR_ID\": \"JaneDoe123\", \"call_date\": \"2024-02-01\", \"call_time\": \"02:16:43\", \"llm_model\": \"anthropic.claude-v2:1\"}\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (AllAccessDisabled) when calling the PutObject operation: All access to this object has been disabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Write Bedrock output text to S3 object  \u001b[39;00m\n\u001b[1;32m     12\u001b[0m s3_key \u001b[38;5;241m=\u001b[39m s3_key_score \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCall score \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m call_date \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m call_time \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 13\u001b[0m \u001b[43ms3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbedrock_response\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBucket\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_bucket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mKey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ms3_key\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscript score assessment written to S3:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m s3_key)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:553\u001b[0m, in \u001b[0;36mClientCreator._create_api_method.<locals>._api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    550\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() only accepts keyword arguments.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    551\u001b[0m     )\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[0;32m--> 553\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/botocore/client.py:1009\u001b[0m, in \u001b[0;36mBaseClient._make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     error_code \u001b[38;5;241m=\u001b[39m error_info\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryErrorCode\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m error_info\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m   1006\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1007\u001b[0m     )\n\u001b[1;32m   1008\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mfrom_code(error_code)\n\u001b[0;32m-> 1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (AllAccessDisabled) when calling the PutObject operation: All access to this object has been disabled"
     ]
    }
   ],
   "source": [
    "# Construct the call summary as JSON object with all relevant attributes and save it to S3\n",
    "bedrock_response = json.loads(call_assessment.json())\n",
    "bedrock_response [\"call_ID\"] = transcript_dict['call_ID']\n",
    "bedrock_response [\"CSR_ID\"] = transcript_dict['CSR_ID']\n",
    "bedrock_response [\"call_date\"] = call_date\n",
    "bedrock_response [\"call_time\"] = call_time\n",
    "bedrock_response [\"llm_model\"] = llm_modelId\n",
    "bedrock_response = json.dumps (bedrock_response)\n",
    "print (bedrock_response)\n",
    "\n",
    "# Write Bedrock output text to S3 object  \n",
    "s3_key = s3_key_score + \"Call score \" + call_date + \" \" + call_time + \".json\"\n",
    "s3.put_object(Body=bedrock_response, Bucket=s3_bucket, Key=s3_key )\n",
    "\n",
    "print(\"Transcript score assessment written to S3:\" + s3_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End of the Notebook"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
